# from sklearn.ensemble import RandomForestClassifier
# from sklearn.ensemble import GradientBoostingClassifier
# from sklearn import linear_model
# from sklearn.tree import DecisionTreeClassifier
import os
import matplotlib.pyplot as plt
from sklearn import tree
from sklearn.metrics import roc_auc_score
from verticapy import vDataFrame
import numpy as np
import pandas as pd
import vertica_python
# from verticapy.connect import *
from lrtree.fit import _fit_parallelized
from scripts.traitement_data import traitement_train, traitement_val, donnes_cacf
# from scripts.traitement_data import extreme_values

conn_info = {"host": os.environ.get("IP_VERTICA"),
             "port": 5433,
             "user": "LK1ASASVIEW",
             "password": os.environ.get("MDP_VERTICA"),
             "database": "LKPRD2",
             # autogenerated session label by default,
             "session_label": "some_label",
             # default throw error on invalid UTF-8 results
             "unicode_error": "strict",
             # SSL is disabled by default
             "ssl": False,
             # using server-side prepared statements is disabled by default
             "use_prepared_statements": False,
             # connection timeout is not enabled by default
             # 5 seconds timeout for a socket operation (Establishing a TCP connection or read/write operation)
             "connection_timeout": 100000}


if __name__ == "__main__":
    # Variables utilisées par le retail (tous segments cumulés)
    Used = ["DAV_Null_EHB_DAV", "DAV_Null_SLD_MOY_CREDITEUR_M", "DAV_Null_SOLDE_MOYEN_FLUX_12M",
            "DAV_Null_SOLDE_MOYEN_M",
            "DAV_Null_SOLDE_MINIMUM_12M", "DAV_Null_FLX_DBT_NBOPE_DEB_12", "DAV_Null_MNT_REFUS_PAIEMENT_M",
            "DAV_Null_MNT_REFUS_PAIEMT_12M", "DAV_Null_NB_REFUS_PAIEMT_3M", "DAV_Null_NB_REFUS_PAIEMT_6M",
            "DAV_Null_NB_REFUS_PAIEMT_M", "DAV_Null_NBPREL_ORG_FINANC_6M", "DAV_Null_NB_TOT_JOURS_DEP_3M",
            "DAV_Null_NB_TOT_JOURS_DEP_M", "DAV_Null_NB_TOT_JOURS_DEP_12M", "DAV_Null_NB_TOT_JOURS_DEP_6M",
            "DAV_Null_NB_TOT_PMT_CARTE_12M", "DAV_Null_NBTOT_JOURS_DEBIT_6M", "DAV_Null_NB_OPE_DEBIT_12M",
            "DAV_Null_NB_CARTES_DAV", "DAV_Null_NBJOURS_DPS_DEPASS",
            "DAV_Null_CPT_JOURS_CONS_DEP_M", "INTERETS_DAV_FLUX", "INTERETS_DEBIT_12M_TIERS",
            "CRED_Null_MAXJOUR_CONS_RET_12M", "CRED_Null_MNT_TOT_IMPAYE_CON", "CRED_Null_NB_JOURS_MAX_RETARD",
            "CRED_Null_NB_JOURS_CONS_RETARD", "ENGAGEMENTS_HORS_BILAN_GR_Calc", "EPARGNE_TOTALE", "EPARGNE_LOGEMENT_GR",
            "EPARGNE_LIVRET_GR", "ENCOURS_RETARD_INF90", "ENCOURS_RETARD_SUP90", "ANCIEN_RELATION_G_RISQUE",
            "INDIC_PERS_INTERDIT_BANC", "Regroup_CSP_Initiale", "CAPACITE_JURIDIQUE", "Categ_NAF_Pro_Agri",
            "TOP_SEUIL_New_def", "DETTES_CT_DETTES_TOT_TIERS", "DETTES_TOT_FLUX_CRED_TIERS", "DETTES_TOT_FLUX_CRED_PRO",
            "NB_MOIS_CREATION_ENTREP", "segment", "incident"]

    # # Avec la colonne qui donne le segment
    # data = pd.read_pickle("dataa_app_seg_inc.pkl")

    # X_train, labels, enc, scaler, merged_cat, discret_cat = traitement_train(data[Used + ["Defaut_12_Mois_contagion"]])
    # print(X_train)
    # Paramètres utilisés : Regroupement seuil = 0.05
    # labels = ['Categ_NAF_Pro_Agri_0 - Aquaculture peche - Autre activite PRO - Divers - Eau, dechet - Energie - Etude - Forêt - Immobilier - Industrie - Élevage de porcins - Administratif - Culture céréales - Culture et élevage', 'Categ_NAF_Pro_Agri_Agriculture - Banque assurance - Social - Commerce - Vaches laitières', 'Categ_NAF_Pro_Agri_Bovins et ruminant - Culture de la vigne - Santé - Fruits et légumes', 'Categ_NAF_Pro_Agri_Construction - Transport - Élevage volailles - Restauration', 'Regroup_CSP_Initiale_0 - Chomeur', "Regroup_CSP_Initiale_Agriculteur - Artisan - Chef d'entreprise - Commercant", 'Regroup_CSP_Initiale_Cadre - Etudiant - Sans activite', 'Regroup_CSP_Initiale_Employes', 'Regroup_CSP_Initiale_Fonct pub armée - Prof intermediaire - Profession liberale', 'Regroup_CSP_Initiale_Retraite', 'CAPACITE_JURIDIQUE_00 - 02 - 04 - 05 - 06', 'CAPACITE_JURIDIQUE_01', 'CAPACITE_JURIDIQUE_03', 'CAPACITE_JURIDIQUE_07 - 08', 'segment_Agri', 'segment_Asso', 'segment_Part', 'segment_Pp', 'segment_Pro', 'incident_0', 'incident_1', 'DAV_Null_EHB_DAV_1', 'DAV_Null_EHB_DAV_2', 'DAV_Null_EHB_DAV_3', 'DAV_Null_EHB_DAV_4', 'DAV_Null_EHB_DAV_5', 'DAV_Null_SLD_MOY_CREDITEUR_M_1', 'DAV_Null_SLD_MOY_CREDITEUR_M_2', 'DAV_Null_SLD_MOY_CREDITEUR_M_3', 'DAV_Null_SLD_MOY_CREDITEUR_M_4', 'DAV_Null_SOLDE_MOYEN_FLUX_12M_1', 'DAV_Null_SOLDE_MOYEN_FLUX_12M_2', 'DAV_Null_SOLDE_MOYEN_FLUX_12M_3', 'DAV_Null_SOLDE_MOYEN_FLUX_12M_4', 'DAV_Null_SOLDE_MOYEN_FLUX_12M_5', 'DAV_Null_SOLDE_MOYEN_FLUX_12M_6', 'DAV_Null_SOLDE_MOYEN_FLUX_12M_7', 'DAV_Null_SOLDE_MOYEN_M_1', 'DAV_Null_SOLDE_MOYEN_M_2', 'DAV_Null_SOLDE_MOYEN_M_3', 'DAV_Null_SOLDE_MOYEN_M_4', 'DAV_Null_SOLDE_MOYEN_M_5', 'DAV_Null_SOLDE_MOYEN_M_6', 'DAV_Null_SOLDE_MINIMUM_12M_1', 'DAV_Null_SOLDE_MINIMUM_12M_2', 'DAV_Null_SOLDE_MINIMUM_12M_3', 'DAV_Null_SOLDE_MINIMUM_12M_4', 'DAV_Null_SOLDE_MINIMUM_12M_5', 'DAV_Null_SOLDE_MINIMUM_12M_6', 'DAV_Null_SOLDE_MINIMUM_12M_7', 'DAV_Null_FLX_DBT_NBOPE_DEB_12_1', 'DAV_Null_FLX_DBT_NBOPE_DEB_12_2', 'DAV_Null_FLX_DBT_NBOPE_DEB_12_3', 'DAV_Null_FLX_DBT_NBOPE_DEB_12_4', 'DAV_Null_FLX_DBT_NBOPE_DEB_12_5', 'DAV_Null_FLX_DBT_NBOPE_DEB_12_6', 'DAV_Null_FLX_DBT_NBOPE_DEB_12_7', 'DAV_Null_MNT_REFUS_PAIEMENT_M_1', 'DAV_Null_MNT_REFUS_PAIEMENT_M_2', 'DAV_Null_MNT_REFUS_PAIEMT_12M_1', 'DAV_Null_MNT_REFUS_PAIEMT_12M_2', 'DAV_Null_MNT_REFUS_PAIEMT_12M_3', 'DAV_Null_MNT_REFUS_PAIEMT_12M_4', 'DAV_Null_MNT_REFUS_PAIEMT_12M_5', 'DAV_Null_NB_REFUS_PAIEMT_3M_1', 'DAV_Null_NB_REFUS_PAIEMT_3M_2', 'DAV_Null_NB_REFUS_PAIEMT_3M_3', 'DAV_Null_NB_REFUS_PAIEMT_6M_1', 'DAV_Null_NB_REFUS_PAIEMT_6M_2', 'DAV_Null_NB_REFUS_PAIEMT_6M_3', 'DAV_Null_NB_REFUS_PAIEMT_6M_4', 'DAV_Null_NB_REFUS_PAIEMT_M_1', 'DAV_Null_NB_REFUS_PAIEMT_M_2', 'DAV_Null_NBPREL_ORG_FINANC_6M_1', 'DAV_Null_NBPREL_ORG_FINANC_6M_2', 'DAV_Null_NBPREL_ORG_FINANC_6M_3', 'DAV_Null_NBPREL_ORG_FINANC_6M_4', 'DAV_Null_NBPREL_ORG_FINANC_6M_5', 'DAV_Null_NB_TOT_JOURS_DEP_3M_1', 'DAV_Null_NB_TOT_JOURS_DEP_3M_2', 'DAV_Null_NB_TOT_JOURS_DEP_3M_3', 'DAV_Null_NB_TOT_JOURS_DEP_3M_4', 'DAV_Null_NB_TOT_JOURS_DEP_M_1', 'DAV_Null_NB_TOT_JOURS_DEP_M_2', 'DAV_Null_NB_TOT_JOURS_DEP_12M_1', 'DAV_Null_NB_TOT_JOURS_DEP_12M_2', 'DAV_Null_NB_TOT_JOURS_DEP_12M_3', 'DAV_Null_NB_TOT_JOURS_DEP_12M_4', 'DAV_Null_NB_TOT_JOURS_DEP_6M_1', 'DAV_Null_NB_TOT_JOURS_DEP_6M_2', 'DAV_Null_NB_TOT_JOURS_DEP_6M_3', 'DAV_Null_NB_TOT_JOURS_DEP_6M_4', 'DAV_Null_NB_TOT_JOURS_DEP_6M_5', 'DAV_Null_NB_TOT_PMT_CARTE_12M_1', 'DAV_Null_NB_TOT_PMT_CARTE_12M_2', 'DAV_Null_NB_TOT_PMT_CARTE_12M_3', 'DAV_Null_NB_TOT_PMT_CARTE_12M_4', 'DAV_Null_NB_TOT_PMT_CARTE_12M_5', 'DAV_Null_NB_TOT_PMT_CARTE_12M_6', 'DAV_Null_NBTOT_JOURS_DEBIT_6M_1', 'DAV_Null_NBTOT_JOURS_DEBIT_6M_2', 'DAV_Null_NBTOT_JOURS_DEBIT_6M_3', 'DAV_Null_NBTOT_JOURS_DEBIT_6M_4', 'DAV_Null_NBTOT_JOURS_DEBIT_6M_5', 'DAV_Null_NB_OPE_DEBIT_12M_1', 'DAV_Null_NB_OPE_DEBIT_12M_2', 'DAV_Null_NB_OPE_DEBIT_12M_3', 'DAV_Null_NB_OPE_DEBIT_12M_4', 'DAV_Null_NB_OPE_DEBIT_12M_5', 'DAV_Null_NB_OPE_DEBIT_12M_6', 'DAV_Null_NB_CARTES_DAV_1', 'DAV_Null_NB_CARTES_DAV_2', 'DAV_Null_NB_CARTES_DAV_3', 'DAV_Null_NB_CARTES_DAV_4', 'DAV_Null_NBJOURS_DPS_DEPASS_1', 'DAV_Null_NBJOURS_DPS_DEPASS_2', 'DAV_Null_NBJOURS_DPS_DEPASS_3', 'DAV_Null_NBJOURS_DPS_DEPASS_4', 'DAV_Null_NBJOURS_DPS_DEPASS_5', 'DAV_Null_NBJOURS_DPS_DEPASS_6', 'DAV_Null_NBJOURS_DPS_DEPASS_7', 'DAV_Null_CPT_JOURS_CONS_DEP_M_1', 'DAV_Null_CPT_JOURS_CONS_DEP_M_2', 'INTERETS_DAV_FLUX_1', 'INTERETS_DAV_FLUX_2', 'INTERETS_DAV_FLUX_3', 'INTERETS_DAV_FLUX_4', 'INTERETS_DAV_FLUX_5', 'INTERETS_DEBIT_12M_TIERS_1', 'INTERETS_DEBIT_12M_TIERS_2', 'INTERETS_DEBIT_12M_TIERS_3', 'INTERETS_DEBIT_12M_TIERS_4', 'INTERETS_DEBIT_12M_TIERS_5', 'CRED_Null_MAXJOUR_CONS_RET_12M_1', 'CRED_Null_MAXJOUR_CONS_RET_12M_2', 'CRED_Null_MNT_TOT_IMPAYE_CON_1', 'CRED_Null_MNT_TOT_IMPAYE_CON_2', 'CRED_Null_NB_JOURS_MAX_RETARD_1', 'CRED_Null_NB_JOURS_MAX_RETARD_2', 'CRED_Null_NB_JOURS_CONS_RETARD_1', 'CRED_Null_NB_JOURS_CONS_RETARD_2', 'ENGAGEMENTS_HORS_BILAN_GR_Calc_1', 'ENGAGEMENTS_HORS_BILAN_GR_Calc_2', 'ENGAGEMENTS_HORS_BILAN_GR_Calc_3', 'ENGAGEMENTS_HORS_BILAN_GR_Calc_4', 'ENGAGEMENTS_HORS_BILAN_GR_Calc_5', 'ENGAGEMENTS_HORS_BILAN_GR_Calc_6', 'ENGAGEMENTS_HORS_BILAN_GR_Calc_7', 'EPARGNE_TOTALE_1', 'EPARGNE_TOTALE_2', 'EPARGNE_TOTALE_3', 'EPARGNE_TOTALE_4', 'EPARGNE_TOTALE_5', 'EPARGNE_TOTALE_6', 'EPARGNE_TOTALE_7', 'EPARGNE_LOGEMENT_GR_1', 'EPARGNE_LOGEMENT_GR_3', 'EPARGNE_LOGEMENT_GR_4', 'EPARGNE_LOGEMENT_GR_5', 'EPARGNE_LOGEMENT_GR_6', 'EPARGNE_LOGEMENT_GR_7', 'EPARGNE_LIVRET_GR_1', 'EPARGNE_LIVRET_GR_2', 'EPARGNE_LIVRET_GR_3', 'EPARGNE_LIVRET_GR_4', 'EPARGNE_LIVRET_GR_5', 'ENCOURS_RETARD_INF90_1', 'ENCOURS_RETARD_INF90_2', 'ENCOURS_RETARD_SUP90_1', 'ENCOURS_RETARD_SUP90_2', 'ANCIEN_RELATION_G_RISQUE_1', 'ANCIEN_RELATION_G_RISQUE_2', 'ANCIEN_RELATION_G_RISQUE_3', 'ANCIEN_RELATION_G_RISQUE_4', 'ANCIEN_RELATION_G_RISQUE_5', 'ANCIEN_RELATION_G_RISQUE_6', 'ANCIEN_RELATION_G_RISQUE_7', 'INDIC_PERS_INTERDIT_BANC_1', 'INDIC_PERS_INTERDIT_BANC_2', 'TOP_SEUIL_New_def_1', 'TOP_SEUIL_New_def_2', 'DETTES_CT_DETTES_TOT_TIERS_1', 'DETTES_CT_DETTES_TOT_TIERS_2', 'DETTES_TOT_FLUX_CRED_TIERS_1', 'DETTES_TOT_FLUX_CRED_TIERS_2', 'DETTES_TOT_FLUX_CRED_TIERS_3', 'DETTES_TOT_FLUX_CRED_TIERS_4', 'DETTES_TOT_FLUX_CRED_TIERS_5', 'DETTES_TOT_FLUX_CRED_TIERS_6', 'DETTES_TOT_FLUX_CRED_PRO_1', 'DETTES_TOT_FLUX_CRED_PRO_2', 'DETTES_TOT_FLUX_CRED_PRO_3', 'DETTES_TOT_FLUX_CRED_PRO_4', 'NB_MOIS_CREATION_ENTREP_1', 'NB_MOIS_CREATION_ENTREP_2', 'NB_MOIS_CREATION_ENTREP_3', 'NB_MOIS_CREATION_ENTREP_4', 'NB_MOIS_CREATION_ENTREP_5']

    # X_train = data[Used].copy()
    # X_train = extreme_values(X_train, missing=False)
    # column_names={'par_0': 'DAV_Null_EHB_DAV', 'par_1': 'DAV_Null_SLD_MOY_CREDITEUR_M', 'par_2': 'DAV_Null_SOLDE_MOYEN_FLUX_12M', 'par_3': 'DAV_Null_SOLDE_MOYEN_M', 'par_4': 'DAV_Null_SOLDE_MINIMUM_12M', 'par_5': 'DAV_Null_FLX_DBT_NBOPE_DEB_12', 'par_6': 'DAV_Null_MNT_REFUS_PAIEMENT_M', 'par_7': 'DAV_Null_MNT_REFUS_PAIEMT_12M', 'par_8': 'DAV_Null_NB_REFUS_PAIEMT_3M', 'par_9': 'DAV_Null_NB_REFUS_PAIEMT_6M', 'par_10': 'DAV_Null_NB_REFUS_PAIEMT_M', 'par_11': 'DAV_Null_NBPREL_ORG_FINANC_6M', 'par_12': 'DAV_Null_NB_TOT_JOURS_DEP_3M', 'par_13': 'DAV_Null_NB_TOT_JOURS_DEP_M', 'par_14': 'DAV_Null_NB_TOT_JOURS_DEP_12M', 'par_15': 'DAV_Null_NB_TOT_JOURS_DEP_6M', 'par_16': 'DAV_Null_NB_TOT_PMT_CARTE_12M', 'par_17': 'DAV_Null_NBTOT_JOURS_DEBIT_6M', 'par_18': 'DAV_Null_NB_OPE_DEBIT_12M', 'par_19': 'DAV_Null_NB_CARTES_DAV', 'par_20': 'DAV_Null_NBJOURS_DPS_DEPASS', 'par_21': 'DAV_Null_CPT_JOURS_CONS_DEP_M', 'par_22': 'INTERETS_DAV_FLUX', 'par_23': 'INTERETS_DEBIT_12M_TIERS', 'par_24': 'CRED_Null_MAXJOUR_CONS_RET_12M', 'par_25': 'CRED_Null_MNT_TOT_IMPAYE_CON', 'par_26': 'CRED_Null_NB_JOURS_MAX_RETARD', 'par_27': 'CRED_Null_NB_JOURS_CONS_RETARD', 'par_28': 'ENGAGEMENTS_HORS_BILAN_GR_Calc', 'par_29': 'EPARGNE_TOTALE', 'par_30': 'EPARGNE_LOGEMENT_GR', 'par_31': 'EPARGNE_LIVRET_GR', 'par_32': 'ENCOURS_RETARD_INF90', 'par_33': 'ENCOURS_RETARD_SUP90', 'par_34': 'ANCIEN_RELATION_G_RISQUE', 'par_35': 'INDIC_PERS_INTERDIT_BANC', 'par_36': 'Regroup_CSP_Initiale', 'par_37': 'CAPACITE_JURIDIQUE', 'par_38': 'Categ_NAF_Pro_Agri', 'par_39': 'TOP_SEUIL_New_def', 'par_40': 'DETTES_CT_DETTES_TOT_TIERS', 'par_41': 'DETTES_TOT_FLUX_CRED_TIERS', 'par_42': 'DETTES_TOT_FLUX_CRED_PRO', 'par_43': 'NB_MOIS_CREATION_ENTREP', 'par_44': 'segment', 'par_45': 'incident'}

    # X_train, labels, enc, scaler, merged_cat, discret_cat = traitement_train(data[Used + ["Defaut_12_Mois_contagion"]])

    # y = data["Defaut_12_Mois_contagion"].replace(["N", "O"], [0, 1])
    # y_train = y.astype(np.int32)

    # Données crca
    data_crca = pd.read_sas("base_crca.sas7bdat")
    # Données lcl
    data_lcl = pd.read_sas("base_lcl.sas7bdat")
    # Données de sofinco
    data_edm = pd.read_sas("base_edm.sas7bdat")
    data_cc = pd.read_sas("base_cc.sas7bdat")
    data_gd = pd.read_sas("base_gd_vf.sas7bdat")
    data_auto = pd.read_sas("base_auto_vf.sas7bdat")
    data_instist = pd.read_sas("base_inst_vf.sas7bdat")
    # score2 entre 168 et 391 pour crca ?
    # segments = grscor2 = [b'1A', b'1C', b'1D', b'1J', b'1M', b'1P', b'1U', b'1Y', b'2U', b'2L', b'3L']
    Common = ['id', 'DOFFR', 'DNAISS', 'DNACJ', 'DEMBA', 'AMEMBC', 'DCLEM', 'HABIT', 'SITFAM', 'CSP', 'CSPCJ',
              'TOP_COEMP', 'CPCL', 'PROD', 'SPROD', 'CPROVS', 'MREVNU', 'MREVCJ', 'MREVAU', 'MRCJAU', 'MCDE', 'CREDAC', 'APPORT', 'ENDEXT', 'NBENF', 'MLOYER', 'MT_LOYER', 'MT_CHRG', 'MT_PENS_DU', 'ECJCOE', 'RFMD', 'AMCIRC', 'NATB', 'CVFISC', 'cible', 'grscor2', 'score2']
    Used = ['DNAISS', 'DNACJ', 'DEMBA', 'AMEMBC', 'DCLEM', 'HABIT', 'SITFAM', 'CSP', 'CSPCJ', 'TOP_COEMP', 'CPCL',
            'PROD', 'SPROD', 'CPROVS', 'MREVNU', 'MREVCJ', 'MREVAU', 'MRCJAU', 'MCDE', 'CREDAC', 'APPORT', 'ENDEXT',
            'NBENF', 'MLOYER', 'MT_LOYER', 'MT_CHRG', 'MT_PENS_DU', 'ECJCOE', 'RFMD', 'AMCIRC', 'NATB', 'CVFISC',
            'grscor2']
    Cate = ['HABIT', 'SITFAM', 'CSP', 'CSPCJ', 'TOP_COEMP', 'PROD', 'SPROD', 'CPROVS', 'NBENF', 'ECJCOE', 'NATB',
            'CVFISC', 'grscor2']
    data = pd.concat([data_crca[Common], data_lcl[Common], data_edm[Common], data_cc[Common], data_gd[Common],
                      data_auto[Common], data_instist[Common]], ignore_index=True)

    data = donnes_cacf(data)
    train_rows = np.random.choice(2372086, 100000, replace=False)
    data_train=data[data.index.isin(train_rows)]
    data_val=data.drop(train_rows)
    y_train = data_train["cible"].astype(np.int32).to_numpy()
    y_val=data_val["cible"].astype(np.int32).to_numpy()

    X_train, labels, enc, scaler, merged_cat, discret_cat = traitement_train(data_train[Used + ["cible"]])
    print(X_train)

    print("GlmTree SEM :")
    model = _fit_parallelized(X_train, y_train, criterion="gini", algo='SEM', nb_init=8, tree_depth=3, class_num=8,
                              max_iter=200, validation=True, data_treatment=False, optimal_size=True)

    tree.plot_tree(model.best_link, feature_names=labels)
    plt.show()
    plt.close()
    text_representation = tree.export_text(model.best_link)
    print(text_representation)
    # print(model.best_link)
    # print(model.best_logreg)
    # print([model.best_logreg[i].coef_ for i in range(len(model.best_logreg))])
    print("Nb segments :", len(model.best_logreg))

    # print("Régression logistique :")
    # modele_regLog = linear_model.LogisticRegression(random_state=0, solver='liblinear', multi_class='auto',
    #                                                 max_iter=100)
    # modele_regLog.fit(X_train, y_train)
    #
    #
    # print("Arbre de décision :")
    # model_tree = DecisionTreeClassifier(min_samples_leaf=500, random_state=0)
    # model_tree.fit(X_train, y_train)
    #
    #
    # print("Gradient Boosting :")
    # model_boost = GradientBoostingClassifier(min_samples_leaf=100, random_state=0)
    # model_boost.fit(X_train, y_train)
    #
    #
    # print("Random forest :")
    # model_forest = RandomForestClassifier(n_estimators=500, min_samples_leaf=100, random_state=0)
    # model_forest.fit(X_train, y_train)

    y_total_train = []
    y_total_proba = []
    for seg in np.unique(data["grscor2"]) :
        print(seg)
        sub_data=data[data["grscor2"] == seg]
        X_test = traitement_val(sub_data[Used], enc, scaler, merged_cat, discret_cat)
        y_test=sub_data['cible'].to_numpy()
        y_proba = model.predict_proba(X_test)
        print("SEM : ", roc_auc_score(y_test, y_proba))
        y_total_train = [*y_total_train, *y_test]
        y_total_proba = [*y_total_proba, *y_proba]
    print("SEM total : ", roc_auc_score(y_total_train, y_total_proba))

    y_total_train = []
    y_total_proba = []

    for base in [data_gd, data_cc, data_edm, data_instist, data_auto, data_crca, data_lcl]:
        sub_base=donnes_cacf(base[Common])
        X_test = traitement_val(sub_base[Used], enc, scaler, merged_cat, discret_cat)
        y_test = sub_base['cible'].to_numpy()
        y_proba = model.predict_proba(X_test)
        print("SEM : ", roc_auc_score(y_test, y_proba))

        y_total_train = [*y_total_train, *y_test]
        y_total_proba = [*y_total_proba, *y_proba]

        print("SEM total : ", roc_auc_score(y_total_train, y_total_proba))

    # print("Totalité des données de validation")
    # table_val = ["LK1ASASVIEW.agri_no_inc_val", "LK1ASASVIEW.agri_inc_val", "LK1ASASVIEW.asso_val",
    #              "LK1ASASVIEW.part_inc_val", "LK1ASASVIEW.part_no_inc_val", "LK1ASASVIEW.pp_inc_val",
    #              "LK1ASASVIEW.pp_no_inc_val", "LK1ASASVIEW.pro_inc_val", "LK1ASASVIEW.pro_no_inc_val"]
    # # segment = ["Agri_no_inc", "Agri_inc", "Asso", "Part_inc", "Part_no_inc", "Pp_inc", "Pp_no_inc", "Pro_inc", "Pro_no_inc"]
    # segment = ["Agri", "Agri", "Asso", "Part", "Part", "Pp", "Pp", "Pro", "Pro"]
    # incident = [0, 1, 0, 1, 0, 1, 0, 1, 0]
    #
    # y_total_train = []
    # y_total_proba = []
    # y_total_proba_reg = []
    # y_total_proba_tree = []
    # y_total_proba_boost = []
    # y_total_proba_forest = []

    # for i in range(len(table_val)):
    #     table = table_val[i]
    #     print(table)
    #     with vertica_python.connect(**conn_info) as connection:
    #         cur = connection.cursor("list")
    #         vdf = vDataFrame(table, cur)
    #         n = len(vdf)
    #         k = 0
    #         y_train = []
    #         y_proba = []
    #         # y_proba_reg = []
    #         # y_proba_tree=[]
    #         # y_proba_boost=[]
    #         # y_proba_forest=[]
    #
    #         while k + 10000 < n:
    #             columns = Used + ["Defaut_12_Mois_contagion"]
    #             data_val_part = vdf.iloc(limit=10000, offset=k, columns=columns).to_pandas()
    #             data_val_part["segment"] = segment[i]
    #             data_val_part["incident"] = incident[i]
    #             k = k + 10000
    #             X_test = traitement_val(data_val_part[Used + ["Defaut_12_Mois_contagion"]], enc, scaler, merged_cat,
    #                                     discret_cat)
    #             # X_test = extreme_values(data_val_part[Used], missing=False)
    #             y_train = [*y_train,
    #                        *data_val_part["Defaut_12_Mois_contagion"].replace(["N", "O"], [0, 1]).astype(np.int32)]
    #             y_proba = [*y_proba, *model.predict_proba(X_test, column_names)]
    #             # proba = modele_regLog.predict_proba(X_test)
    #             # y_proba_reg = [*y_proba_reg, *[proba[i][1] for i in range(len(proba))]]
    #             # proba = model_tree.predict_proba(X_test)
    #             # y_proba_tree = [*y_proba_tree, *[proba[i][1] for i in range(len(proba))]]
    #             # proba = model_boost.predict_proba(X_test)
    #             # y_proba_boost = [*y_proba_boost, *[proba[i][1] for i in range(len(proba))]]
    #             # proba = model_forest.predict_proba(X_test)
    #             # y_proba_forest = [*y_proba_forest, *[proba[i][1] for i in range(len(proba))]]
    #
    #     y_total_train = [*y_total_train, *y_train]
    #     y_total_proba = [*y_total_proba, *y_proba]
    #     y_total_proba_reg=[*y_total_proba_reg, *y_proba_reg]
    #     y_total_proba_tree=[*y_total_proba_tree, *y_proba_tree]
    #     y_total_proba_boost=[*y_total_proba_boost, *y_proba_boost]
    #     y_total_proba_forest=[*y_total_proba_forest, *y_proba_forest]
    #
    #     print("SEM : ", roc_auc_score(y_train, y_proba))
    #     print("Reglog : ", roc_auc_score(y_train, y_proba_reg))
    #     print("Tree : ", roc_auc_score(y_train, y_proba_tree))
    #     print("Boost : ", roc_auc_score(y_train, y_proba_boost))
    #     print("Forest : ", roc_auc_score(y_train, y_proba_forest))

    # print("SEM total : ", roc_auc_score(y_total_train, y_total_proba))
    # print("Reglog total : ", roc_auc_score(y_total_train, y_total_proba_reg))
    # print("Tree total : ", roc_auc_score(y_total_train, y_total_proba_tree))
    # print("Boost total : ", roc_auc_score(y_total_train, y_total_proba_boost))
    # print("Forest total : ", roc_auc_score(y_total_train, y_total_proba_forest))