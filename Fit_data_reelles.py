# from sklearn.ensemble import RandomForestClassifier
# from sklearn.ensemble import GradientBoostingClassifier
# from sklearn import linear_model
# from sklearn.tree import DecisionTreeClassifier

from sklearn.metrics import roc_auc_score
from sklearn import tree
import matplotlib.pyplot as plt
from glmtree.fit import fit_parralized

from verticapy.connect import *
from verticapy import vDataFrame

from traitement_data import *

conn_info = {"host": "10.56.122.83",
             "port": 5433,
             "user": "LK1ASASVIEW",
             "password": "Vert1c@_2018",
             "database": "LKPRD2",
             # autogenerated session label by default,
             "session_label": "some_label",
             # default throw error on invalid UTF-8 results
             "unicode_error": "strict",
             # SSL is disabled by default
             "ssl": False,
             # using server-side prepared statements is disabled by default
             "use_prepared_statements": False,
             # connection timeout is not enabled by default
             # 5 seconds timeout for a socket operation (Establishing a TCP connection or read/write operation)
             "connection_timeout": 100000}

# table_val=["LK1ASASVIEW.score_agri_no_inc_val", "LK1ASASVIEW.score_agri_inc_val", "LK1ASASVIEW.score_asso_val", "LK1ASASVIEW.score_part_inc_val", "LK1ASASVIEW.score_pro_inc_val", "LK1ASASVIEW.score_pp_inc_val", "LK1ASASVIEW.score_pro_no_inc_val", "LK1ASASVIEW.score_part_no_inc_val", "LK1ASASVIEW.score_pp_no_inc_val"]
# y_total_train=[]
# y_total_proba=[]
# for table in table_val :
#     print(table)
#     with vertica_python.connect(**conn_info) as connection:
#         cur = connection.cursor("list")
#         vdf = vDataFrame(table, cur)
#         n = len(vdf)
#         k = 0
#         y_proba = []
#         y_train = []
#         while k + 10000 < n:
#             data_val_part = vdf.iloc(limit=10000, offset=k, columns=["Defaut_12_Mois_contagion", "P_1"]).to_pandas()
#             k = k + 10000
#             y_train_part=data_val_part["Defaut_12_Mois_contagion"].replace(["N", "O"], [0, 1]).astype(np.int32)
#             y_proba_part=data_val_part["P_1"]
#             to_remove=np.isnan(y_proba_part)
#             j=0
#             for i in range(len(y_train_part)):
#                 if to_remove[i]:
#                     y_train_part.pop(i-j)
#                     y_proba_part.pop(i-j)
#                     j=j+1
#             y_proba=[*y_proba, *y_proba_part]
#             y_train=[*y_train, *y_train_part]
#     y_total_train = [*y_total_train, *y_train]
#     y_total_proba = [*y_total_proba, *y_proba]
#     print(roc_auc_score(y_train, y_proba))
# print("ROC total", roc_auc_score(y_total_train, y_total_proba))


if __name__ == "__main__":
    # Variables utilisées par le retail (tous segments cumulés)
    Used = ["DAV_Null_EHB_DAV", "DAV_Null_SLD_MOY_CREDITEUR_M", "DAV_Null_SOLDE_MOYEN_FLUX_12M",
            "DAV_Null_SOLDE_MOYEN_M",
            "DAV_Null_SOLDE_MINIMUM_12M", "DAV_Null_FLX_DBT_NBOPE_DEB_12", "DAV_Null_MNT_REFUS_PAIEMENT_M",
            "DAV_Null_MNT_REFUS_PAIEMT_12M", "DAV_Null_NB_REFUS_PAIEMT_3M", "DAV_Null_NB_REFUS_PAIEMT_6M",
            "DAV_Null_NB_REFUS_PAIEMT_M", "DAV_Null_NBPREL_ORG_FINANC_6M", "DAV_Null_NB_TOT_JOURS_DEP_3M",
            "DAV_Null_NB_TOT_JOURS_DEP_M", "DAV_Null_NB_TOT_JOURS_DEP_12M", "DAV_Null_NB_TOT_JOURS_DEP_6M",
            "DAV_Null_NB_TOT_PMT_CARTE_12M", "DAV_Null_NBTOT_JOURS_DEBIT_6M", "DAV_Null_NB_OPE_DEBIT_12M",
            "DAV_Null_NB_CARTES_DAV", "DAV_Null_NBJOURS_DPS_DEPASS",
            "DAV_Null_CPT_JOURS_CONS_DEP_M", "INTERETS_DAV_FLUX", "INTERETS_DEBIT_12M_TIERS",
            "CRED_Null_MAXJOUR_CONS_RET_12M", "CRED_Null_MNT_TOT_IMPAYE_CON", "CRED_Null_NB_JOURS_MAX_RETARD",
            "CRED_Null_NB_JOURS_CONS_RETARD", "ENGAGEMENTS_HORS_BILAN_GR_Calc", "EPARGNE_TOTALE", "EPARGNE_LOGEMENT_GR",
            "EPARGNE_LIVRET_GR", "ENCOURS_RETARD_INF90", "ENCOURS_RETARD_SUP90", "ANCIEN_RELATION_G_RISQUE",
            "INDIC_PERS_INTERDIT_BANC", "Regroup_CSP_Initiale", "CAPACITE_JURIDIQUE", "Categ_NAF_Pro_Agri",
            "TOP_SEUIL_New_def", "DETTES_CT_DETTES_TOT_TIERS", "DETTES_TOT_FLUX_CRED_TIERS", "DETTES_TOT_FLUX_CRED_PRO",
            "NB_MOIS_CREATION_ENTREP", "segment"]
    # "segment"

    # # Sans la colonne qui donne le segment
    # data = pd.read_pickle("data_app.pkl")
    # data_val = pd.read_pickle("data_val.pkl")

    # # Avec la colonne qui donne le segment
    data = pd.read_pickle("dataa_app.pkl")
    data_val = pd.read_pickle("dataa_val.pkl")

    X_train, labels, enc, scaler, merged_cat, discret_cat = traitement_train(data[Used + ["Defaut_12_Mois_contagion"]])
    print(X_train)
    print(X_train.shape)
    X_test = traitement_val(data_val[Used + ["Defaut_12_Mois_contagion"]], enc, scaler, merged_cat, discret_cat)
    print(X_test.shape)

    y = data["Defaut_12_Mois_contagion"].replace(["N", "O"], [0, 1])
    y_train = y.astype(np.int32)
    y = data_val["Defaut_12_Mois_contagion"].replace(["N", "O"], [0, 1])
    y_test = y.astype(np.int32)


    print("GlmTree SEM :")
    model = fit_parralized(X_train, y_train, criterion="gini", algo='SEM', nb_init=4, tree_depth=10, class_num=9,
                           max_iter=100, min_impurity_decrease=0.0001, validation=True)

    tree.plot_tree(model.best_link, feature_names=labels)
    plt.show()
    plt.close()
    print(model.best_logreg)
    print([model.best_logreg[i].coef_ for i in range(len(model.best_logreg))])

    y_proba = model.predict_proba(X_train)
    print("SEM test : ", roc_auc_score(y_train, y_proba))

    # print("Régression logistique :")
    # modele_regLog = linear_model.LogisticRegression(random_state=0, solver='liblinear', multi_class='auto',
    #                                                 max_iter=100)
    # modele_regLog.fit(X_train, y_train)
    # proba = modele_regLog.predict_proba(X_train)
    # y_proba = [proba[i][1] for i in range(len(proba))]
    # print("Reglog test : ", roc_auc_score(y_train, y_proba))
    #
    #
    # print("Arbre de décision :")
    # model_tree = DecisionTreeClassifier(min_samples_leaf=500, random_state=0)
    # model_tree.fit(X_train, y_train)
    # proba = model_tree.predict_proba(X_train)
    # y_proba = [proba[i][1] for i in range(len(proba))]
    # print("Arbre test : ", roc_auc_score(y_train, y_proba))
    #
    #
    # print("Gradient Boosting :")
    # model_boost = GradientBoostingClassifier(min_samples_leaf=100, random_state=0)
    # model_boost.fit(X_train, y_train)
    # proba = model_boost.predict_proba(X_train)
    # y_proba = [proba[i][1] for i in range(len(proba))]
    # print("GradBoost test : ", roc_auc_score(y_train, y_proba))
    #
    #
    # print("Random forest :")
    # model_forest = RandomForestClassifier(n_estimators=500, min_samples_leaf=100, random_state=0)
    # model_forest.fit(X_train, y_train)
    # proba = model_forest.predict_proba(X_train)
    # y_proba = [proba[i][1] for i in range(len(proba))]
    # print("Forest test : ", roc_auc_score(y_train, y_proba))


    print("Totalité des données de validation")
    table_val = ["LK1ASASVIEW.agri_no_inc_val", "LK1ASASVIEW.agri_inc_val", "LK1ASASVIEW.asso_val",
                 "LK1ASASVIEW.part_inc_val", "LK1ASASVIEW.part_no_inc_val", "LK1ASASVIEW.pp_inc_val",
                 "LK1ASASVIEW.pp_no_inc_val", "LK1ASASVIEW.pro_inc_val", "LK1ASASVIEW.pro_no_inc_val"]
    segment = ["Agri_no_inc", "Agri_inc", "Asso", "Part_inc", "Part_no_inc", "Pp_inc", "Pp_no_inc", "Pro_inc",
               "Pro_no_inc"]

    y_total_train=[]
    y_total_proba=[]
    # y_total_proba_reg = []
    # y_total_proba_tree = []
    # y_total_proba_boost = []
    # y_total_proba_forest = []

    for i in range(len(table_val)):
        table = table_val[i]
        print(table)
        # with vertica_python.connect(**conn_info) as connection:
        #     cur = connection.cursor("list")
        #     vdf = vDataFrame(table, cur)
        #     y_train = []
        #     y_proba = []
        #     # y_proba_reg = []
        #     # y_proba_tree = []
        #     # y_proba_boost = []
        #     # y_proba_forest = []
        #     columns = Used + ["Defaut_12_Mois_contagion"]
        #     data_val_part = vdf.iloc(limit=50000, columns=columns).to_pandas()
        #     data_val_part["segment"] = segment[i]
        #     X_test = traitement_val(data_val_part[Used], enc, scaler, merged_cat)
        #     y_train = [*y_train,
        #                *data_val_part["Defaut_12_Mois_contagion"].replace(["N", "O"], [0, 1]).astype(np.int32)]
        #     y_proba = [*y_proba, *model.predict_proba(X_test)]
        #     # proba = modele_regLog.predict_proba(X_test)
        #     # y_proba_reg = [*y_proba_reg, *[proba[i][1] for i in range(len(proba))]]
        #     # proba = model_tree.predict_proba(X_test)
        #     # y_proba_tree = [*y_proba_tree, *[proba[i][1] for i in range(len(proba))]]
        #     # proba = model_boost.predict_proba(X_test)
        #     # y_proba_boost = [*y_proba_boost, *[proba[i][1] for i in range(len(proba))]]
        #     # proba = model_forest.predict_proba(X_test)
        #     # y_proba_forest = [*y_proba_forest, *[proba[i][1] for i in range(len(proba))]]

        with vertica_python.connect(**conn_info) as connection:
            cur = connection.cursor("list")
            vdf = vDataFrame(table, cur)
            n = len(vdf)
            k = 0
            y_proba = []
            # y_proba_reg = []
            # y_train = []
            # y_proba_tree=[]
            # y_proba_boost=[]
            # y_proba_forest=[]

            while k + 10000 < n:
                columns = Used + ["Defaut_12_Mois_contagion"]
                data_val_part = vdf.iloc(limit=10000, offset=k, columns=columns).to_pandas()
                data_val_part["segment"] = segment[i]
                k = k + 10000
                X_test = traitement_val(data_val_part[Used + ["Defaut_12_Mois_contagion"]], enc, scaler, merged_cat, discret_cat)
                y_train = [*y_train,
                           *data_val_part["Defaut_12_Mois_contagion"].replace(["N", "O"], [0, 1]).astype(np.int32)]
                y_proba = [*y_proba, *model.predict_proba(X_test)]
                # proba = modele_regLog.predict_proba(X_test)
                # y_proba_reg = [*y_proba_reg, *[proba[i][1] for i in range(len(proba))]]
                # proba = model_tree.predict_proba(X_test)
                # y_proba_tree = [*y_proba_tree, *[proba[i][1] for i in range(len(proba))]]
                # proba = model_boost.predict_proba(X_test)
                # y_proba_boost = [*y_proba_boost, *[proba[i][1] for i in range(len(proba))]]
                # proba = model_forest.predict_proba(X_test)
                # y_proba_forest = [*y_proba_forest, *[proba[i][1] for i in range(len(proba))]]

        y_total_train=[*y_total_train, *y_train]
        y_total_proba=[*y_total_proba, *y_proba]
        # y_total_proba_reg=[*y_total_proba_reg, *y_proba_reg]
        # y_total_proba_tree=[*y_total_proba_tree, *y_proba_tree]
        # y_total_proba_boost=[*y_total_proba_boost, *y_proba_boost]
        # y_total_proba_forest=[*y_total_proba_forest, *y_proba_forest]

        print("SEM : ", roc_auc_score(y_train, y_proba))
        # print("Reglog : ", roc_auc_score(y_train, y_proba_reg))
        # print("Tree : ", roc_auc_score(y_train, y_proba_tree))
        # print("Boost : ", roc_auc_score(y_train, y_proba_boost))
        # print("Forest : ", roc_auc_score(y_train, y_proba_forest))

    print("SEM total : ", roc_auc_score(y_total_train, y_total_proba))
    # print("Reglog total : ", roc_auc_score(y_total_train, y_total_proba_reg))
    # print("Tree total : ", roc_auc_score(y_total_train, y_total_proba_tree))
    # print("Boost total : ", roc_auc_score(y_total_train, y_total_proba_boost))
    # print("Forest total : ", roc_auc_score(y_total_train, y_total_proba_forest))